{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-115fd4e224d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import pygame\n",
    "import time\n",
    "import random\n",
    "pygame.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-06e4a440cbd2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#resizing of image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpic1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:\\ATL2019\\DBS'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mnum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpic1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/*.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'glob' is not defined"
     ]
    }
   ],
   "source": [
    "#resizing of image\n",
    "pic1 = glob.glob('C:\\ATL2019\\DBS')\n",
    "num = 0\n",
    "for i in pic1:\n",
    "    for j in glob.glob(i+'/*.jpg'):\n",
    "        print(j)\n",
    "        pic = cv2.imread(j)\n",
    "        pic2 = cv2.resize(pic, (64,64))\n",
    "        cv2.imwrite('C:\\ATL2019\\DNS\\img.' + str(num) + '.jpg',pic2)\n",
    "        num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-39f6fda07c2e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCascadeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Documents/haarcascade_frontalface_default.xml\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msrc_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"C:\\ATL2019\\DNS\\*.*\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mgray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "fc = cv2.CascadeClassifier(\"Documents/haarcascade_frontalface_default.xml\");\n",
    "src_path=\"C:\\ATL2019\\DNS\\*.*\"\n",
    "for file in glob.glob(src_path):\n",
    "    im = cv2.imread(file)\n",
    "    gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    faces = fc.detectMultiScale(gray,scaleFactor = 1.3, minNeighbors = 3, minSize = (5, 5))\n",
    "    print(faces)\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(im,(x,y),(x+w, y+h), (0, 255, 0), 2)\n",
    "    plt.imshow(im)\n",
    "    plt.show()      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-9ca550144951>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'C:\\ATL2019\\DNS'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrecognizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mface\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLBPHFaceRecognizer_create\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdetector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCascadeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Documents/haarcascade_frontalface_default.xml\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# function to get the images and label data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgetImagesAndLabels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "path = 'C:\\ATL2019\\DNS'\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "detector = cv2.CascadeClassifier(\"Documents/haarcascade_frontalface_default.xml\");\n",
    "# function to get the images and label data\n",
    "def getImagesAndLabels(path):\n",
    "    imagePaths = [os.path.join(path,f) for f in os.listdir(path)]    \n",
    "    faceSamples=[]\n",
    "    ids = []\n",
    "    for imagePath in imagePaths:\n",
    "        PIL_img = Image.open(imagePath).convert('L') # grayscale\n",
    "        img_numpy = np.array(PIL_img,'uint8')\n",
    "        id = int(os.path.split(imagePath)[-1].split(\".\")[1])\n",
    "        faces = detector.detectMultiScale(img_numpy)\n",
    "        for (x,y,w,h) in faces:\n",
    "            faceSamples.append(img_numpy[y:y+h,x:x+w])\n",
    "            ids.append(id)\n",
    "    return faceSamples,ids\n",
    "print (\"\\n [INFO] Training faces. It will take a few seconds. Wait ...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'getImagesAndLabels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-6abea3e802bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfaces\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetImagesAndLabels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mrecognizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfaces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Save the model into trainer/trainer.yml\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mrecognizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/FOR/trainer.yml'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Print the numer of faces trained and end program\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'getImagesAndLabels' is not defined"
     ]
    }
   ],
   "source": [
    "faces,ids = getImagesAndLabels(path)\n",
    "recognizer.train(faces, np.array(ids))\n",
    "# Save the model into trainer/trainer.yml\n",
    "recognizer.write('C:/FOR/trainer.yml') \n",
    "# Print the numer of faces trained and end program\n",
    "print(\"\\n [INFO] {0} faces trained. Exiting Program\".format(len(np.unique(ids))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing for images from camera\n",
    "pygame.init()\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "recognizer.read('C:/FOR/trainer.yml') \n",
    "cascadePath = \"Documents/haarcascade_frontalface_default.xml\"\n",
    "faceCascade = cv2.CascadeClassifier(cascadePath);\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "#iniciate id counter\n",
    "id = 0\n",
    "# names related to ids: example ==> Marcelo: id=1,  etc\n",
    "names = ['none'] \n",
    "# Initialize and start realtime video capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize and start realtime video capture\n",
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(3, 640) # set video widht\n",
    "cam.set(4, 480) # set video height\n",
    "# Define min window size to be recognized as a face\n",
    "minW = 0.1*cam.get(3)\n",
    "minH = 0.1*cam.get(4)\n",
    "fc = cv2.CascadeClassifier(\"Documents/haarcascade_frontalface_default.xml\");\n",
    "while True:\n",
    "    ret, img =cam.read()\n",
    "    #print(img)\n",
    "    #img = cv2.flip(img, -1) # Flip verticallfc = cv2.CascadeClassifier(\"Documents/haarcascade_frontalface_default.xml\");y\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    print(gray)\n",
    "    faces = fc.detectMultiScale( \n",
    "        gray,\n",
    "        scaleFactor = 1.2,\n",
    "        minNeighbors = 5,\n",
    "        minSize = (int(minW), int(minH)),\n",
    "       )\n",
    "    print(faces)\n",
    "    #print(\"hi\")\n",
    "    for(x,y,w,h) in faces:\n",
    "        cv2.rectangle(img, (x,y), (x+w,y+h), (0,255,0), 2)\n",
    "        id, confidence = recognizer.predict(gray[y:y+h,x:x+w])\n",
    "        print(confidence)\n",
    "        # If confidence is less them 100 ==> \"0\" : perfect match \n",
    "        if (confidence > 100):\n",
    "            src_path=\"C:\\ATL2019\\DNS\\*.*\"\n",
    "            #print (src_path)\n",
    "            for file in glob.glob(src_path):\n",
    "                #print(file)\n",
    "                emotion_dict= {'Angry': 0, 'Sad': 5, 'Crying': 2, 'Surprised': 6, 'Happy': 3}\n",
    "                #Reading image\n",
    "                face_image  = cv2.imread(file)\n",
    "                #print(face_image.shape)\n",
    "                #reasizing imag\n",
    "                face_image = cv2.cvtColor(face_image,cv2.COLOR_BGR2GRAY)\n",
    "                face_image=cv2.resize(face_image,(48,48))\n",
    "                #print(face_image)\n",
    "                face_image = np.reshape(face_image, [1, face_image.shape[0], face_image.shape[1], 1])\n",
    "                #Load the model trained for detecting emotions of a fac\n",
    "                model = load_model('C:\\ATL2019\\model_v6_23.hdf5')\n",
    "                #print(face_image.shape)\n",
    "                predicted_class = np.argmax(model.predict(face_image))\n",
    "                #np.argmax(model.predict(face_image))\n",
    "                #Predicted labe\n",
    "                label_map = dict((v,k) for k,v in emotion_dict.items())\n",
    "                predicted_label = label_map[predicted_class]\n",
    "                #print(predicted_label)\n",
    "                language = 'en'\n",
    "                #speech = gTTS(text = predicted_label, lang = language, slow = 0)\n",
    "                #speech.save('\\hello.mp3')\n",
    "                pygame.mixer.music.load(\"C:\\KPV\\SNG.mp3\")\n",
    "                pygame.mixer.music.play(-1)\n",
    "        confidence = \"  {0}%\".format(round(100 - confidence))\n",
    "       # else:\n",
    "        #    id = \"unknown\"\n",
    "        #confidence = \"  {0}%\".format(round(100 - confidence))\n",
    "        cv2.putText(\n",
    "                    img, \n",
    "                    str(predicted_label), \n",
    "                    (x+5,y+h-5), \n",
    "                    font, \n",
    "                    1, \n",
    "                    (255,255,0), \n",
    "                    1\n",
    "                   )  \n",
    "        \n",
    "    \n",
    "    plt.imshow(img) \n",
    "    plt.show()\n",
    "    cam.release()\n",
    "    #k = cv2.waitKey(10) & 0xff # Press 'ESC' for exiting video\n",
    "    #if k == 27:\n",
    "    break\n",
    "# Do a bit of cleanup\n",
    "print(\"\\n [INFO] Exiting Program and cleanup stuff\")\n",
    "\n",
    "#cv2.destroyAllWindows()\n",
    "\n",
    "for text to speech\n",
    "\n",
    "import os\n",
    "import keras\n",
    "import face_recognition\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "#from gtts import gTTS\n",
    "import pygame\n",
    "import time\n",
    "import random\n",
    "from pygame import mixer\n",
    "from gtts import gTTS\n",
    "\n",
    "import pygame as pg\n",
    "def play_music(music_file, volume=0.8):\n",
    "    '''\n",
    "    stream music with mixer.music module in a blocking manner\n",
    "    this will stream the sound from disk while playing\n",
    "    '''\n",
    "    # set up the mixer\n",
    "    freq = 44100     # audio CD quality\n",
    "    bitsize = -16    # unsigned 16 bit\n",
    "    channels = 2     # 1 is mono, 2 is stereo\n",
    "    buffer = 2048    # number of samples (experiment to get best sound)\n",
    "    pg.mixer.init(freq, bitsize, channels, buffer)\n",
    "    # volume value 0.0 to 1.0\n",
    "    pg.mixer.music.set_volume(volume)\n",
    "    clock = pg.time.Clock()\n",
    "    try:\n",
    "        pg.mixer.music.load(music_file)\n",
    "        print(\"Music file {} loaded!\".format(music_file))\n",
    "    except pg.error:\n",
    "        print(\"File {} not found! ({})\".format(music_file, pg.get_error()))\n",
    "        return\n",
    "    pg.mixer.music.play()\n",
    "    while pg.mixer.music.get_busy():\n",
    "        # check if playback has finished\n",
    "        clock.tick(30)\n",
    "    quit()\n",
    "# pick a MP3 music file you have in the working folder\n",
    "# otherwise give the full file path\n",
    "# (try other sound file formats too)\n",
    "# optional volume 0 to 1.0\n",
    "print(\"before if\")\n",
    "if(predicted_label == 'Happy' ):\n",
    "    music_file = \"HAD.mp3\"\n",
    "    print(\"inside if\")\n",
    "elif(predicted_label == 'Surprised'):\n",
    "    music_file = \"SUR.mp3\"\n",
    "elif(predicted_label =='Crying'):\n",
    "    music_file = \"CRY.mp3\"\n",
    "elif(predicted_label == 'Sad'):\n",
    "    music_file = \"SAD.mp3\"\n",
    "else :\n",
    "    music_file = \"ANGRY.mp3\"\n",
    "print(\"after if else ladder\")\n",
    "volume = 0.8   \n",
    "    \n",
    "play_music(music_file, volume)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "code from website\n",
    "\n",
    "\n",
    "''' pg_playmp3f.py\n",
    "play MP3 music files using Python module pygame\n",
    "pygame is free from: http://www.pygame.org\n",
    "(does not create a GUI frame in this case)\n",
    "'''\n",
    "import pygame as pg\n",
    "def play_music(music_file, volume=0.8):\n",
    "    '''\n",
    "    stream music with mixer.music module in a blocking manner\n",
    "    this will stream the sound from disk while playing\n",
    "    '''\n",
    "    # set up the mixer\n",
    "    freq = 44100     # audio CD quality\n",
    "    bitsize = -16    # unsigned 16 bit\n",
    "    channels = 2     # 1 is mono, 2 is stereo\n",
    "    buffer = 2048    # number of samples (experiment to get best sound)\n",
    "    pg.mixer.init(freq, bitsize, channels, buffer)\n",
    "    # volume value 0.0 to 1.0\n",
    "    pg.mixer.music.set_volume(volume)\n",
    "    clock = pg.time.Clock()\n",
    "    try:\n",
    "        pg.mixer.music.load(music_file)\n",
    "        print(\"Music file {} loaded!\".format(music_file))\n",
    "    except pg.error:\n",
    "        print(\"File {} not found! ({})\".format(music_file, pg.get_error()))\n",
    "        return\n",
    "    pg.mixer.music.play()\n",
    "    while pg.mixer.music.get_busy():\n",
    "        # check if playback has finished\n",
    "        clock.tick(30)\n",
    "# pick a MP3 music file you have in the working folder\n",
    "# otherwise give the full file path\n",
    "# (try other sound file formats too)\n",
    "music_file = \"Hot80s.mp3\"\n",
    "# optional volume 0 to 1.0\n",
    "volume = 0.8\n",
    "play_music(music_file, volume)\n",
    "\n",
    "\n",
    "\n",
    "code from website modified \n",
    "\n",
    "import pygame as pg\n",
    "def play_music(music_file, volume=1.0):\n",
    "    '''\n",
    "    stream music with mixer.music module in a blocking manner\n",
    "    this will stream the sound from disk while playing\n",
    "    '''\n",
    "    # set up the mixer\n",
    "    freq = 44100     # audio CD quality\n",
    "    bitsize = -16    # unsigned 16 bit\n",
    "    channels = 2     # 1 is mono, 2 is stereo\n",
    "    buffer = 2048    # number of samples (experiment to get best sound)\n",
    "    pg.mixer.init(freq, bitsize, channels, buffer)\n",
    "    # volume value 0.0 to 1.0\n",
    "    pg.mixer.music.set_volume(volume)\n",
    "    clock = pg.time.Clock()\n",
    "    try:\n",
    "        pg.mixer.music.load(music_file)\n",
    "        print(\"Music file {} loaded!\".format(music_file))\n",
    "    except pg.error:\n",
    "        print(\"File {} not found! ({})\".format(music_file, pg.get_error()))\n",
    "        return\n",
    "    pg.mixer.music.play()\n",
    "    while pg.mixer.music.get_busy():\n",
    "        # check if playback has finished\n",
    "        clock.tick(30)\n",
    "# pick a MP3 music file you have in the working folder\n",
    "# otherwise give the full file path\n",
    "# (try other sound file formats too)\n",
    "music_file = \"SUR.mp3\"\n",
    "# optional volume 0 to 1.0\n",
    "volume = 0.8\n",
    "quit()\n",
    "#if(predicted_label == 'Surprised'):\n",
    "   # print(\"hi\")\n",
    "play_music(music_file, volume)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
